{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f90b477-f8af-41e8-a5dc-0a1e23e23e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this notebook, I'll be creating a simple dataset \n",
    "#that we can use to train up a toy model. \n",
    "#This dataset will be based on the match to a particular motif, CCATGT\n",
    "#The score at each position in the genome will be based on how similar \n",
    "#it is to the motif.\n",
    "MOTIF=\"CCATGT\"\n",
    "OTHER_MOTIF=\"TATAGT\"\n",
    "WORKING_DIRECTORY=\"/n/projects/cm2363/chrombpnet-heavy/test/simpleDemo\"\n",
    "SRC_DIR=\"/n/projects/cm2363/chrombpnet-heavy/src\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c9d0b46-b767-432b-82ad-ca4cb67d5508",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirname in [\"input\", \"data\", \"bed\", \"models\", \"shap\", \"json\", \"pred\", \"modisco\"]:\n",
    "    !mkdir -p {WORKING_DIRECTORY}/{DIRNAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bcc368e-282a-4896-9d83-7f01ce911932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pysam\n",
    "import pyBigWig\n",
    "import numpy as np\n",
    "import json\n",
    "import scipy.ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fba9da8f-7f50-4721-83b0-c16ea60533c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENOME_FASTA = \"/n/data1/genomes/S_cerevisiae/sacCer3/all_chr.fa\"\n",
    "CHROM_SIZES = \"/n/data1/genomes/indexes/sacCer3/extras/sacCer3.chrom.sizes\"\n",
    "genome = pysam.FastaFile(GENOME_FASTA)\n",
    "bwHeader = []\n",
    "for ref in genome.references:\n",
    "    bwHeader.append((ref, genome.get_reference_length(ref)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f71c8c16-91d6-4068-95c4-6e04cc969bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_CHROMS = genome.references[:2]\n",
    "VAL_CHROMS = genome.references[2:4]\n",
    "TRAIN_CHROMS = genome.references[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39e5e0ac-4160-4958-b099-045e130b9746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScore(motif, sequence):\n",
    "    score = 1\n",
    "    for i, c in enumerate(motif):\n",
    "        if(sequence[i] == c):\n",
    "            score *= 2\n",
    "    return max(0.0, score-4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdf96bf9-b598-4de0-954f-057ba6d6b873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chrI\n",
      "built\n",
      "chrII\n",
      "built\n",
      "chrIII\n",
      "built\n",
      "chrIV\n",
      "built\n",
      "chrIX\n",
      "built\n",
      "chrM\n",
      "built\n",
      "chrV\n",
      "built\n",
      "chrVI\n",
      "built\n",
      "chrVII\n",
      "built\n",
      "chrVIII\n",
      "built\n",
      "chrX\n",
      "built\n",
      "chrXI\n",
      "built\n",
      "chrXII\n",
      "built\n",
      "chrXIII\n",
      "built\n",
      "chrXIV\n",
      "built\n",
      "chrXV\n",
      "built\n",
      "chrXVI\n",
      "built\n",
      "closing\n"
     ]
    }
   ],
   "source": [
    "with pyBigWig.open(WORKING_DIRECTORY + \"/data/testData.bw\", \"w\") as outBw:\n",
    "    outBw.addHeader(bwHeader)\n",
    "    for chrom in genome.references:\n",
    "        print(chrom)\n",
    "        vals = []\n",
    "        otherVals = []\n",
    "        chromSeq = genome.fetch(chrom, 0, genome.get_reference_length(chrom))\n",
    "        for pos in range(genome.get_reference_length(chrom)-len(MOTIF)):\n",
    "            seq = chromSeq[pos:pos+len(MOTIF)]\n",
    "            scoreVal = getScore(MOTIF, seq)\n",
    "            scoreOther = getScore(OTHER_MOTIF, seq)\n",
    "            vals.append(scoreVal)\n",
    "            otherVals.append(scoreOther)\n",
    "        print(\"built\")\n",
    "        smoothVals = scipy.ndimage.gaussian_filter1d(otherVals, 15)*5\n",
    "        smoothVals += scipy.ndimage.gaussian_filter1d(otherVals, 5)*2\n",
    "        smoothVals += scipy.ndimage.gaussian_filter(vals, 1)\n",
    "        smoothVals += np.array(vals)\n",
    "        outBw.addEntries(chrom, 0, values=list(smoothVals), span=1, step=1)\n",
    "    print(\"closing\")\n",
    "    outBw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac25bb07-0cd9-4fd5-88f5-8aeab6b474ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#So this bigwig will have two components to it - one will be a low-frequency \n",
    "#response to MOTIF_OTHER, and the second will be a very local response to MOTIF.\n",
    "#I sure hope a neural network can learn something so simple! \n",
    "#In order to train, I need to generate training regions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "226df178-37b7-460c-819d-6fb6d4f68fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_LENGTH=1000\n",
    "N_LAYERS=6\n",
    "CONV1_SIZE=7\n",
    "PCONV_SIZE=25\n",
    "input_length_str = !{SRC_DIR}/lengthCalc.py --output-len {OUTPUT_LENGTH} --n-dil-layers {N_LAYERS} --conv1-kernel-size {CONV1_SIZE} --profile-kernel-size {PCONV_SIZE} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f144b15-4188-40df-b3cf-cb298542d0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1282\n",
      "283\n"
     ]
    }
   ],
   "source": [
    "INPUT_LENGTH=int(input_length_str[0])\n",
    "print(INPUT_LENGTH)\n",
    "RECEPTIVE_FIELD=INPUT_LENGTH - OUTPUT_LENGTH+1\n",
    "print(RECEPTIVE_FIELD)\n",
    "MAX_JITTER = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "700a402f-0d13-4c60-b64d-f07f5508db19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybedtools\n",
    "def generateTilingRegions(genome, width, chromEdgeBoundary, spaceBetween, allowChroms):\n",
    "    chromRegions = []\n",
    "    numRegions = 0\n",
    "    #To use window_maker from pybedtools, I first need to create a bed containing the chromosomes where I want regions made. \n",
    "    for chrom in genome.references:\n",
    "        if(chrom not in allowChroms):\n",
    "            continue\n",
    "         \n",
    "        startPos = chromEdgeBoundary\n",
    "        chromSize = genome.get_reference_length(chrom)\n",
    "        stopPos = chromSize - chromEdgeBoundary\n",
    "        chromRegions.append(pybedtools.Interval(chrom, startPos, stopPos))\n",
    "     \n",
    "    windows = pybedtools.BedTool(chromRegions).window_maker(w=width, \n",
    "                                                            s=spaceBetween + width, \n",
    "                                                            g=CHROM_SIZES)\n",
    "    return windows\n",
    "\n",
    "with pysam.FastaFile(GENOME_FASTA) as genomeFp:\n",
    "    w = generateTilingRegions(genomeFp, OUTPUT_LENGTH, 10000, 5000, TEST_CHROMS + TRAIN_CHROMS + VAL_CHROMS)\n",
    "    w.saveas(WORKING_DIRECTORY+ \"/bed/tiling_all.bed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddcc1086-97a8-4028-ace4-1aec703fb9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"bigwigs\": [\n",
      "        {\n",
      "            \"file-name\": \"/n/projects/cm2363/chrombpnet-heavy/test/simpleDemo/data/testData.bw\",\n",
      "            \"max-quantile\": 1,\n",
      "            \"min-quantile\": 0.01\n",
      "        }\n",
      "    ],\n",
      "    \"splits\": {\n",
      "        \"test-chroms\": [\n",
      "            \"chrI\",\n",
      "            \"chrII\"\n",
      "        ],\n",
      "        \"val-chroms\": [\n",
      "            \"chrIII\",\n",
      "            \"chrIV\"\n",
      "        ],\n",
      "        \"train-chroms\": [\n",
      "            \"chrIX\",\n",
      "            \"chrM\",\n",
      "            \"chrV\",\n",
      "            \"chrVI\",\n",
      "            \"chrVII\",\n",
      "            \"chrVIII\",\n",
      "            \"chrX\",\n",
      "            \"chrXI\",\n",
      "            \"chrXII\",\n",
      "            \"chrXIII\",\n",
      "            \"chrXIV\",\n",
      "            \"chrXV\",\n",
      "            \"chrXVI\"\n",
      "        ],\n",
      "        \"regions\": [\n",
      "            \"/n/projects/cm2363/chrombpnet-heavy/test/simpleDemo/bed/tiling_all.bed\"\n",
      "        ]\n",
      "    },\n",
      "    \"genome\": \"/n/data1/genomes/S_cerevisiae/sacCer3/all_chr.fa\",\n",
      "    \"write-counts-to\": \"/n/projects/cm2363/chrombpnet-heavy/test/simpleDemo/bed/nonpeak_all.stats\",\n",
      "    \"output-length\": 1000,\n",
      "    \"input-length\": 1282,\n",
      "    \"max-jitter\": 100,\n",
      "    \"output-prefix\": \"/n/projects/cm2363/chrombpnet-heavy/test/simpleDemo/bed/peak\",\n",
      "    \"resize-mode\": \"center\",\n",
      "    \"verbosity\": \"INFO\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "biasBwSpec = [{\"file-name\" : WORKING_DIRECTORY+\"/data/testData.bw\", \"max-quantile\" : 1, \"min-quantile\" : 0.01}]\n",
    "prepareBedNonPeaksConfig = {\n",
    "    \"bigwigs\" : biasBwSpec, \n",
    "    \"splits\" : {\"test-chroms\"  : TEST_CHROMS, \n",
    "                \"val-chroms\"   : VAL_CHROMS,\n",
    "                \"train-chroms\" : TRAIN_CHROMS,\n",
    "                \"regions\" : [WORKING_DIRECTORY + \"/bed/tiling_all.bed\"]},\n",
    "    \"genome\" : GENOME_FASTA,\n",
    "    \"output-length\" : OUTPUT_LENGTH,\n",
    "    \"input-length\" : INPUT_LENGTH,\n",
    "    \"max-jitter\" : MAX_JITTER,\n",
    "    \"output-prefix\" : WORKING_DIRECTORY + \"/bed/peak\", \n",
    "    \"resize-mode\" : \"center\", \n",
    "    \"verbosity\" : \"INFO\"}\n",
    "\n",
    "with open(WORKING_DIRECTORY + \"/json/prepareBedPeaks.json\", \"w\") as fp:\n",
    "    json.dump(prepareBedNonPeaksConfig, fp, indent=4)\n",
    "    print(json.dumps(prepareBedNonPeaksConfig, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a781f39b-5774-481b-9f1b-2d018b41f0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting bed file generation.\n",
      "INFO:root:Training regions: 1552\n",
      "INFO:root:Validation regions: 309\n",
      "INFO:root:Testing regions: 175\n",
      "INFO:root:Rejected on loading: 0\n",
      "INFO:root:Validating training regions.\n",
      "  0%|                                                  | 0/1534 [00:00<?, ?it/s]\n",
      "100%|█████████████████████████████████████| 1534/1534 [00:01<00:00, 1521.31it/s]\n",
      "INFO:root:Total surviving regions: 1518\n",
      "INFO:root:Validating validation regions.\n",
      "  0%|                                                   | 0/307 [00:00<?, ?it/s]\n",
      "100%|███████████████████████████████████████| 307/307 [00:00<00:00, 1530.49it/s]\n",
      "INFO:root:Total surviving regions: 303\n",
      "INFO:root:Validating testing regions.\n",
      "  0%|                                                   | 0/173 [00:00<?, ?it/s]\n",
      "100%|███████████████████████████████████████| 173/173 [00:00<00:00, 1489.92it/s]\n",
      "INFO:root:Total surviving regions: 171\n",
      "INFO:root:Regions saved.\n"
     ]
    }
   ],
   "source": [
    "!{SRC_DIR}/prepareBed.py {WORKING_DIRECTORY}/json/prepareBedPeaks.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c64fda9-ce5b-4956-b782-df843c4ad1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Sequence dataset created.\n",
      "DEBUG:root:Added data for head 0\n",
      "DEBUG:root:Sequence dataset created.\n",
      "DEBUG:root:Added data for head 0\n"
     ]
    }
   ],
   "source": [
    "for split in [\"train\", \"val\"]:\n",
    "    heads = [{\"bigwig-files\" : [WORKING_DIRECTORY+\"/data/testData.bw\"]}]\n",
    "    config = {\"genome\" : GENOME_FASTA, \n",
    "              \"input-length\" : INPUT_LENGTH,\n",
    "              \"output-length\" : OUTPUT_LENGTH,\n",
    "              \"max-jitter\" : MAX_JITTER,\n",
    "              \"regions\" : WORKING_DIRECTORY + \"/bed/peak_\" + split + \".bed\",\n",
    "              \"output-h5\" : WORKING_DIRECTORY + \"/input/\" + split + \".h5\",\n",
    "              \"heads\" : heads,\n",
    "              \"verbosity\" : \"DEBUG\"}\n",
    "    configFname =WORKING_DIRECTORY + \"/json/prepareInput_\" + split+ \".json\" \n",
    "    with open(configFname, \"w\") as fp:\n",
    "        json.dump(config, fp)\n",
    "    !{SRC_DIR}/prepareTrainingData.py {configFname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72c0b714-d260-40a0-a216-cd2bfe08d5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"settings\": {\n",
      "        \"output-prefix\": \"/n/projects/cm2363/chrombpnet-heavy/test/simpleDemo/models/solo\",\n",
      "        \"epochs\": 20,\n",
      "        \"early-stopping-patience\": 20,\n",
      "        \"batch-size\": 128,\n",
      "        \"learning-rate\": 0.004,\n",
      "        \"learning-rate-plateau-patience\": 5,\n",
      "        \"max-jitter\": 100,\n",
      "        \"architecture\": {\n",
      "            \"architecture-name\": \"bpnet\",\n",
      "            \"input-length\": 1282,\n",
      "            \"output-length\": 1000,\n",
      "            \"model-name\": \"solo\",\n",
      "            \"model-args\": \"\",\n",
      "            \"filters\": 16,\n",
      "            \"layers\": 6,\n",
      "            \"input-filter-width\": 7,\n",
      "            \"output-filter-width\": 25\n",
      "        }\n",
      "    },\n",
      "    \"train-data\": \"/n/projects/cm2363/chrombpnet-heavy/test/simpleDemo/input/train.h5\",\n",
      "    \"val-data\": \"/n/projects/cm2363/chrombpnet-heavy/test/simpleDemo/input/val.h5\",\n",
      "    \"heads\": [\n",
      "        {\n",
      "            \"num-tasks\": 1,\n",
      "            \"profile-loss-weight\": 1,\n",
      "            \"head-name\": \"solo\",\n",
      "            \"counts-loss-weight\": 10\n",
      "        }\n",
      "    ],\n",
      "    \"verbosity\": \"WARNING\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "heads = [{\"num-tasks\" : 1, \n",
    "          \"profile-loss-weight\" : 1, \n",
    "          \"head-name\" : \"solo\",\n",
    "          \"counts-loss-weight\" : 10}]\n",
    "#print(heads)\n",
    "\n",
    "#And now the whole config file:\n",
    "soloTrainConfig = {\n",
    "    \"settings\" : {\n",
    "        \"output-prefix\" : WORKING_DIRECTORY + \"/models/solo\", \n",
    "        \"epochs\" : 20,\n",
    "        \"early-stopping-patience\" : 20,\n",
    "        \"batch-size\" : 128,\n",
    "        \"learning-rate\" : 0.004,\n",
    "        \"learning-rate-plateau-patience\" : 5,\n",
    "        \"max-jitter\" : 100,\n",
    "        \"architecture\" : {\n",
    "            \"architecture-name\" : \"bpnet\", \n",
    "            \"input-length\" : INPUT_LENGTH,\n",
    "            \"output-length\" : OUTPUT_LENGTH,\n",
    "            \"model-name\" : \"solo\",\n",
    "            \"model-args\" : \"\",\n",
    "            \"filters\" : 16,\n",
    "            \"layers\" : N_LAYERS,\n",
    "            \"input-filter-width\" : CONV1_SIZE,\n",
    "            \"output-filter-width\" : PCONV_SIZE\n",
    "        }\n",
    "    },\n",
    "    \"train-data\" : WORKING_DIRECTORY + \"/input/train.h5\",\n",
    "    \"val-data\" : WORKING_DIRECTORY + \"/input/val.h5\",\n",
    "    \"heads\" : heads,\n",
    "    \"verbosity\" : \"WARNING\"\n",
    "}\n",
    "\n",
    "print(json.dumps(soloTrainConfig, indent=4))\n",
    "\n",
    "with open(WORKING_DIRECTORY + \"/json/trainSolo.json\", \"w\") as fp:\n",
    "    json.dump(soloTrainConfig, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4573db3c-b031-4e9d-8a51-60029c25d108",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 3859.2468 - solo_profile_solo_loss: 3842.3464 - solo_logcounts_solo_loss: 1.6900\n",
      "Epoch 1: val_loss improved from inf to 2872.70142, saving model to /n/projects/cm2363/chrombpnet-heavy/test/simpleDemo/models/solo.checkpoint.model\n",
      "2022-12-07 15:42:31.576694: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "12/12 [==============================] - 11s 462ms/step - loss: 3778.9407 - solo_profile_solo_loss: 3763.2898 - solo_logcounts_solo_loss: 1.5651 - val_loss: 2872.7014 - val_solo_profile_solo_loss: 2872.4390 - val_solo_logcounts_solo_loss: 0.0262 - lr: 0.0040\n",
      "Epoch 2/20\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: 2792.6311 - solo_profile_solo_loss: 2791.4478 - solo_logcounts_solo_loss: 0.1184\n",
      "Epoch 2: val_loss improved from 2872.70142 to 2664.73999, saving model to /n/projects/cm2363/chrombpnet-heavy/test/simpleDemo/models/solo.checkpoint.model\n",
      "12/12 [==============================] - 3s 292ms/step - loss: 2767.5454 - solo_profile_solo_loss: 2766.5884 - solo_logcounts_solo_loss: 0.0957 - val_loss: 2664.7400 - val_solo_profile_solo_loss: 2664.6816 - val_solo_logcounts_solo_loss: 0.0058 - lr: 0.0040\n",
      "Epoch 3/20\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: 2615.5977 - solo_profile_solo_loss: 2615.5056 - solo_logcounts_solo_loss: 0.0092\n",
      "Epoch 3: val_loss improved from 2664.73999 to 2535.09082, saving model to /n/projects/cm2363/chrombpnet-heavy/test/simpleDemo/models/solo.checkpoint.model\n",
      "12/12 [==============================] - 4s 322ms/step - loss: 2603.1836 - solo_profile_solo_loss: 2603.1025 - solo_logcounts_solo_loss: 0.0081 - val_loss: 2535.0908 - val_solo_profile_solo_loss: 2535.0161 - val_solo_logcounts_solo_loss: 0.0075 - lr: 0.0040\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 2483.0457 - solo_profile_solo_loss: 2482.9209 - solo_logcounts_solo_loss: 0.0125\n",
      "Epoch 4: val_loss improved from 2535.09082 to 2433.06787, saving model to /n/projects/cm2363/chrombpnet-heavy/test/simpleDemo/models/solo.checkpoint.model\n",
      "12/12 [==============================] - 3s 296ms/step - loss: 2483.0457 - solo_profile_solo_loss: 2482.9209 - solo_logcounts_solo_loss: 0.0125 - val_loss: 2433.0679 - val_solo_profile_solo_loss: 2432.9912 - val_solo_logcounts_solo_loss: 0.0076 - lr: 0.0040\n",
      "Epoch 5/20\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 2412.4292 - solo_profile_solo_loss: 2412.2773 - solo_logcounts_solo_loss: 0.0152\n",
      "Epoch 5: val_loss improved from 2433.06787 to 2386.60278, saving model to /n/projects/cm2363/chrombpnet-heavy/test/simpleDemo/models/solo.checkpoint.model\n",
      "12/12 [==============================] - 4s 328ms/step - loss: 2411.8914 - solo_profile_solo_loss: 2411.7354 - solo_logcounts_solo_loss: 0.0156 - val_loss: 2386.6028 - val_solo_profile_solo_loss: 2386.5220 - val_solo_logcounts_solo_loss: 0.0081 - lr: 0.0040\n",
      "Epoch 6/20\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 2369.9656 - solo_profile_solo_loss: 2369.9287 - solo_logcounts_solo_loss: 0.0037\n",
      "Epoch 6: val_loss improved from 2386.60278 to 2345.86426, saving model to /n/projects/cm2363/chrombpnet-heavy/test/simpleDemo/models/solo.checkpoint.model\n",
      "12/12 [==============================] - 3s 285ms/step - loss: 2368.5508 - solo_profile_solo_loss: 2368.5120 - solo_logcounts_solo_loss: 0.0039 - val_loss: 2345.8643 - val_solo_profile_solo_loss: 2345.8328 - val_solo_logcounts_solo_loss: 0.0032 - lr: 0.0040\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 2328.5068 - solo_profile_solo_loss: 2328.4585 - solo_logcounts_solo_loss: 0.0048\n",
      "Epoch 7: val_loss improved from 2345.86426 to 2307.26538, saving model to /n/projects/cm2363/chrombpnet-heavy/test/simpleDemo/models/solo.checkpoint.model\n",
      "12/12 [==============================] - 4s 330ms/step - loss: 2328.5068 - solo_profile_solo_loss: 2328.4585 - solo_logcounts_solo_loss: 0.0048 - val_loss: 2307.2654 - val_solo_profile_solo_loss: 2307.1975 - val_solo_logcounts_solo_loss: 0.0068 - lr: 0.0040\n",
      "Epoch 8/20\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 2293.7661 - solo_profile_solo_loss: 2293.7041 - solo_logcounts_solo_loss: 0.0062\n",
      "Epoch 8: val_loss improved from 2307.26538 to 2272.16699, saving model to /n/projects/cm2363/chrombpnet-heavy/test/simpleDemo/models/solo.checkpoint.model\n",
      "12/12 [==============================] - 3s 294ms/step - loss: 2292.3999 - solo_profile_solo_loss: 2292.3394 - solo_logcounts_solo_loss: 0.0060 - val_loss: 2272.1670 - val_solo_profile_solo_loss: 2272.1475 - val_solo_logcounts_solo_loss: 0.0019 - lr: 0.0040\n",
      "Epoch 9/20\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 2262.4072 - solo_profile_solo_loss: 2262.3318 - solo_logcounts_solo_loss: 0.0075\n",
      "Epoch 9: val_loss improved from 2272.16699 to 2246.96753, saving model to /n/projects/cm2363/chrombpnet-heavy/test/simpleDemo/models/solo.checkpoint.model\n",
      "12/12 [==============================] - 4s 331ms/step - loss: 2261.2622 - solo_profile_solo_loss: 2261.1909 - solo_logcounts_solo_loss: 0.0071 - val_loss: 2246.9675 - val_solo_profile_solo_loss: 2246.7998 - val_solo_logcounts_solo_loss: 0.0168 - lr: 0.0040\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 2237.6670 - solo_profile_solo_loss: 2237.5593 - solo_logcounts_solo_loss: 0.0108\n",
      "Epoch 10: val_loss improved from 2246.96753 to 2227.09839, saving model to /n/projects/cm2363/chrombpnet-heavy/test/simpleDemo/models/solo.checkpoint.model\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 2237.6670 - solo_profile_solo_loss: 2237.5593 - solo_logcounts_solo_loss: 0.0108 - val_loss: 2227.0984 - val_solo_profile_solo_loss: 2226.9873 - val_solo_logcounts_solo_loss: 0.0111 - lr: 0.0040\n",
      "Epoch 11/20\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: 2222.8323 - solo_profile_solo_loss: 2222.7456 - solo_logcounts_solo_loss: 0.0087\n",
      "Epoch 11: val_loss improved from 2227.09839 to 2213.64404, saving model to /n/projects/cm2363/chrombpnet-heavy/test/simpleDemo/models/solo.checkpoint.model\n",
      "12/12 [==============================] - 4s 336ms/step - loss: 2221.5554 - solo_profile_solo_loss: 2221.4695 - solo_logcounts_solo_loss: 0.0086 - val_loss: 2213.6440 - val_solo_profile_solo_loss: 2213.4702 - val_solo_logcounts_solo_loss: 0.0174 - lr: 0.0040\n",
      "Epoch 12/20\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 2208.8699 - solo_profile_solo_loss: 2208.7156 - solo_logcounts_solo_loss: 0.0154\n",
      "Epoch 12: val_loss improved from 2213.64404 to 2203.52881, saving model to /n/projects/cm2363/chrombpnet-heavy/test/simpleDemo/models/solo.checkpoint.model\n",
      "12/12 [==============================] - 4s 325ms/step - loss: 2209.3713 - solo_profile_solo_loss: 2209.2214 - solo_logcounts_solo_loss: 0.0150 - val_loss: 2203.5288 - val_solo_profile_solo_loss: 2203.5083 - val_solo_logcounts_solo_loss: 0.0021 - lr: 0.0040\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 2201.4697 - solo_profile_solo_loss: 2201.3640 - solo_logcounts_solo_loss: 0.0106\n",
      "Epoch 13: val_loss improved from 2203.52881 to 2195.69092, saving model to /n/projects/cm2363/chrombpnet-heavy/test/simpleDemo/models/solo.checkpoint.model\n",
      "12/12 [==============================] - 3s 295ms/step - loss: 2201.4697 - solo_profile_solo_loss: 2201.3640 - solo_logcounts_solo_loss: 0.0106 - val_loss: 2195.6909 - val_solo_profile_solo_loss: 2195.4336 - val_solo_logcounts_solo_loss: 0.0257 - lr: 0.0040\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 2193.9941 - solo_profile_solo_loss: 2193.8247 - solo_logcounts_solo_loss: 0.0169\n",
      "Epoch 14: val_loss improved from 2195.69092 to 2190.22803, saving model to /n/projects/cm2363/chrombpnet-heavy/test/simpleDemo/models/solo.checkpoint.model\n",
      "12/12 [==============================] - 4s 340ms/step - loss: 2193.9941 - solo_profile_solo_loss: 2193.8247 - solo_logcounts_solo_loss: 0.0169 - val_loss: 2190.2280 - val_solo_profile_solo_loss: 2190.1909 - val_solo_logcounts_solo_loss: 0.0037 - lr: 0.0040\n",
      "Epoch 15/20\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 2188.4399 - solo_profile_solo_loss: 2188.3442 - solo_logcounts_solo_loss: 0.0095\n",
      "Epoch 15: val_loss improved from 2190.22803 to 2184.69751, saving model to /n/projects/cm2363/chrombpnet-heavy/test/simpleDemo/models/solo.checkpoint.model\n",
      "12/12 [==============================] - 3s 297ms/step - loss: 2188.0513 - solo_profile_solo_loss: 2187.9600 - solo_logcounts_solo_loss: 0.0091 - val_loss: 2184.6975 - val_solo_profile_solo_loss: 2184.5754 - val_solo_logcounts_solo_loss: 0.0122 - lr: 0.0040\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 2182.3989 - solo_profile_solo_loss: 2182.3108 - solo_logcounts_solo_loss: 0.0088\n",
      "Epoch 16: val_loss improved from 2184.69751 to 2180.11646, saving model to /n/projects/cm2363/chrombpnet-heavy/test/simpleDemo/models/solo.checkpoint.model\n",
      "12/12 [==============================] - 4s 325ms/step - loss: 2182.3989 - solo_profile_solo_loss: 2182.3108 - solo_logcounts_solo_loss: 0.0088 - val_loss: 2180.1165 - val_solo_profile_solo_loss: 2180.0247 - val_solo_logcounts_solo_loss: 0.0092 - lr: 0.0040\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 2177.6624 - solo_profile_solo_loss: 2177.5774 - solo_logcounts_solo_loss: 0.0085\n",
      "Epoch 17: val_loss improved from 2180.11646 to 2175.45483, saving model to /n/projects/cm2363/chrombpnet-heavy/test/simpleDemo/models/solo.checkpoint.model\n",
      "12/12 [==============================] - 3s 300ms/step - loss: 2177.6624 - solo_profile_solo_loss: 2177.5774 - solo_logcounts_solo_loss: 0.0085 - val_loss: 2175.4548 - val_solo_profile_solo_loss: 2175.4116 - val_solo_logcounts_solo_loss: 0.0043 - lr: 0.0040\n",
      "Epoch 18/20\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: 2173.5044 - solo_profile_solo_loss: 2173.4329 - solo_logcounts_solo_loss: 0.0071\n",
      "Epoch 18: val_loss improved from 2175.45483 to 2171.48999, saving model to /n/projects/cm2363/chrombpnet-heavy/test/simpleDemo/models/solo.checkpoint.model\n",
      "12/12 [==============================] - 4s 336ms/step - loss: 2173.7490 - solo_profile_solo_loss: 2173.6709 - solo_logcounts_solo_loss: 0.0078 - val_loss: 2171.4900 - val_solo_profile_solo_loss: 2171.3801 - val_solo_logcounts_solo_loss: 0.0110 - lr: 0.0040\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 2170.2913 - solo_profile_solo_loss: 2170.1926 - solo_logcounts_solo_loss: 0.0098\n",
      "Epoch 19: val_loss improved from 2171.48999 to 2167.57812, saving model to /n/projects/cm2363/chrombpnet-heavy/test/simpleDemo/models/solo.checkpoint.model\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 2170.2913 - solo_profile_solo_loss: 2170.1926 - solo_logcounts_solo_loss: 0.0098 - val_loss: 2167.5781 - val_solo_profile_solo_loss: 2167.5227 - val_solo_logcounts_solo_loss: 0.0056 - lr: 0.0040\n",
      "Epoch 20/20\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 2167.4534 - solo_profile_solo_loss: 2167.3748 - solo_logcounts_solo_loss: 0.0079\n",
      "Epoch 20: val_loss improved from 2167.57812 to 2165.08716, saving model to /n/projects/cm2363/chrombpnet-heavy/test/simpleDemo/models/solo.checkpoint.model\n",
      "12/12 [==============================] - 4s 324ms/step - loss: 2167.0732 - solo_profile_solo_loss: 2166.9956 - solo_logcounts_solo_loss: 0.0077 - val_loss: 2165.0872 - val_solo_profile_solo_loss: 2165.0024 - val_solo_logcounts_solo_loss: 0.0085 - lr: 0.0040\n"
     ]
    }
   ],
   "source": [
    "!{SRC_DIR}/trainSoloModel.py {WORKING_DIRECTORY}/json/trainSolo.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b836cf62-1871-45f8-9afe-baaf2e29e377",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictConfig = {\n",
    "    \"settings\" : {\n",
    "        \"genome\" : GENOME_FASTA, \n",
    "        \"output-h5\" : WORKING_DIRECTORY + \"/pred/solo.h5\", \n",
    "        \"batch-size\" : 128,\n",
    "        \"heads\" : 1,\n",
    "        \n",
    "        \"architecture\" : {\n",
    "            \"model-file\" : WORKING_DIRECTORY + \"/models/solo.model\",\n",
    "            \"input-length\" : INPUT_LENGTH,\n",
    "            \"output-length\" : OUTPUT_LENGTH\n",
    "        }\n",
    "    },\n",
    "    \"bed-file\" : WORKING_DIRECTORY + \"/bed/peak_all.bed\",\n",
    "    \"verbosity\" : \"DEBUG\"\n",
    "}\n",
    "\n",
    "\n",
    "with open(WORKING_DIRECTORY + \"/json/predict.json\", \"w\") as fp:\n",
    "    json.dump(predictConfig, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "165fab27-94c3-4170-8101-767e3ccc2105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:GPU memory growth enabled.\n",
      "DEBUG:root:Opening output hdf5 file.\n",
      "INFO:root:Loading regions\n",
      "INFO:root:Input prepared. Loading model.\n",
      "INFO:root:Model loaded. Predicting.\n",
      "16/16 [==============================] - 5s 21ms/step\n",
      "INFO:root:Predictions complete. Writing hdf5.\n",
      "INFO:root:Writing predictions\n",
      "DEBUG:h5py._conv:Creating converter from 5 to 3\n",
      "INFO:root:Datasets created. Populating regions.\n",
      "INFO:root:Writing predictions.\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 116.36it/s]\n",
      "INFO:root:File saved.\n"
     ]
    }
   ],
   "source": [
    "!{SRC_DIR}/makePredictionsBed.py {WORKING_DIRECTORY}/json/predict.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e183ea90-9a50-4970-b4e4-8be1dc47372d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting to write /n/projects/cm2363/chrombpnet-heavy/test/simpleDemo/pred/solo.bw, head 0 task 0\n",
      "INFO:root:Added header.\n",
      "INFO:root:Loading coordinate data\n",
      "INFO:root:Region data loaded. Sorting.\n",
      "100%|██████████████████████████████████| 1992/1992 [00:00<00:00, 1005421.61it/s]\n",
      "INFO:root:Generated list of regions to sort.\n",
      "INFO:root:Region order calculated.\n",
      "INFO:root:Loading head data.\n",
      "INFO:root:Starting to write data.\n",
      "100%|█████████████████████████████████████| 1992/1992 [00:01<00:00, 1578.03it/s]\n",
      "INFO:root:Closing bigwig.\n",
      "INFO:root:Bigwig closed.\n"
     ]
    }
   ],
   "source": [
    "!{SRC_DIR}/predictToBigwig.py \\\n",
    "    --h5 {WORKING_DIRECTORY}/pred/solo.h5 \\\n",
    "    --bw {WORKING_DIRECTORY}/pred/solo.bw \\\n",
    "    --head-id 0 \\\n",
    "    --task-id 0 \\\n",
    "    --mode profile \\\n",
    "    --verbose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e64bd6aa-f8ad-40a6-ae21-1d9493fc64f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reference /n/projects/cm2363/chrombpnet-heavy/test/simpleDemo/data/testData.bw predicted /n/projects/cm2363/chrombpnet-heavy/test/simpleDemo/pred/solo.bw regions /n/projects/cm2363/chrombpnet-heavy/test/simpleDemo/bed/peak_all.bed\n",
      "100%|█████████████████████████████████████| 1992/1992 [00:00<00:00, 5123.97it/s]\n",
      "/n/projects/cm2363/utils/src/anaconda3/envs/bpreveal/lib/python3.10/site-packages/numpy/lib/function_base.py:4486: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "metric    \t      0.000000%\t     25.000000%\t     50.000000%\t     75.000000%\t    100.000000%\tregions\n",
      "mnll      \t            nan\t            nan\t            nan\t            nan\t            nan\t1992\n",
      "jsd       \t       0.021363\t       0.027448\t       0.030071\t       0.033441\t       0.063595\t1992\n",
      "pearsonr  \t       0.964279\t       0.979569\t       0.981933\t       0.983847\t       0.990021\t1992\n",
      "spearmanr \t       0.963865\t       0.981745\t       0.984461\t       0.986796\t       0.993471\t1992\n",
      "Counts pearson \t  0.954834\n",
      "Counts spearman\t  0.972189\n"
     ]
    }
   ],
   "source": [
    "!{SRC_DIR}/metrics.py \\\n",
    "    --reference {WORKING_DIRECTORY}/data/testData.bw \\\n",
    "    --pred {WORKING_DIRECTORY}/pred/solo.bw \\\n",
    "    --regions {WORKING_DIRECTORY}/bed/peak_all.bed \\\n",
    "    --threads 70 \\\n",
    "    --apply-abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd23a28-11c0-45d2-88fe-5d48caf06695",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now it's time to generate importance scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9dd9fbb9-ffd6-4fa1-8002-07d7a0257bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretConfig =  {\n",
    "        \"genome\" : GENOME_FASTA,\n",
    "        \"bed-file\" : WORKING_DIRECTORY + \"/bed/peak_all.bed\",\n",
    "        \"model-file\" : WORKING_DIRECTORY + \"/models/solo.model\", \n",
    "        \"input-length\" : INPUT_LENGTH,\n",
    "        \"output-length\" : OUTPUT_LENGTH,\n",
    "        \"heads\" : 1,\n",
    "        \"head-id\": 0,\n",
    "        \"profile-task-ids\" : [0],\n",
    "        \"profile-h5\" : WORKING_DIRECTORY + \"/shap/profile.h5\",\n",
    "        \"counts-h5\" : WORKING_DIRECTORY + \"/shap/counts.h5\",\n",
    "        \"num-shuffles\" : 20,\n",
    "        \"verbosity\" : \"DEBUG\"}\n",
    "\n",
    "with open(WORKING_DIRECTORY + \"/json/shap.json\", \"w\") as fp:\n",
    "    json.dump(interpretConfig, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c13ca8c5-9f64-479c-b495-244337821f34",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:GPU memory growth enabled.\n",
      "WARNING:tensorflow:From /n/projects/cm2363/chrombpnet-heavy/src/shap.py:145: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /n/projects/cm2363/chrombpnet-heavy/src/shap.py:145: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n",
      "\n",
      "INFO:root:AddV2used in model but handling of op is not specified by shap; will use original  gradients\n",
      "INFO:root:StopGradientused in model but handling of op is not specified by shap; will use original  gradients\n",
      "INFO:root:SpaceToBatchNDused in model but handling of op is not specified by shap; will use original  gradients\n",
      "INFO:root:BatchToSpaceNDused in model but handling of op is not specified by shap; will use original  gradients\n",
      "  0%|                                                  | 0/1992 [00:00<?, ?it/s]2022-12-08 10:42:17.729125: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.66GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-12-08 10:42:17.735176: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.66GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-12-08 10:42:17.741206: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.32GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-12-08 10:42:17.741284: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.32GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-12-08 10:42:18.088465: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.32GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-12-08 10:42:18.088588: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.32GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-12-08 10:42:18.092291: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.66GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-12-08 10:42:18.092365: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.66GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "100%|███████████████████████████████████████| 1992/1992 [00:43<00:00, 45.41it/s]\n",
      "DEBUG:h5py._conv:Creating converter from 5 to 3\n",
      "Tensor(\"strided_slice_2:0\", shape=(None,), dtype=float32)\n",
      "(None,)\n",
      "INFO:root:AddV2used in model but handling of op is not specified by shap; will use original  gradients\n",
      "INFO:root:SpaceToBatchNDused in model but handling of op is not specified by shap; will use original  gradients\n",
      "INFO:root:BatchToSpaceNDused in model but handling of op is not specified by shap; will use original  gradients\n",
      "100%|███████████████████████████████████████| 1992/1992 [00:37<00:00, 52.54it/s]\n"
     ]
    }
   ],
   "source": [
    "!{SRC_DIR}/interpretFlat.py {WORKING_DIRECTORY}/json/shap.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4edacab-b535-463a-8492-05ba846a6c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Bigwig header[('chrI', 230218), ('chrII', 813184), ('chrIII', 316620), ('chrIV', 1531933), ('chrIX', 439888), ('chrM', 85779), ('chrV', 576874), ('chrVI', 270161), ('chrVII', 1090940), ('chrVIII', 562643), ('chrX', 745751), ('chrXI', 666816), ('chrXII', 1078177), ('chrXIII', 924431), ('chrXIV', 784333), ('chrXV', 1091291), ('chrXVI', 948066)]\n",
      "INFO:root:Files opened; writing regions\n",
      "100%|██████████████████████████████████████| 1992/1992 [00:03<00:00, 654.35it/s]\n",
      "INFO:root:Regions written; closing bigwig.\n",
      "INFO:root:Done saving shap scores.\n"
     ]
    }
   ],
   "source": [
    "!{SRC_DIR}/shapToBigwig.py \\\n",
    "    --h5 {WORKING_DIRECTORY}/shap/profile.h5 \\\n",
    "    --bw {WORKING_DIRECTORY}/shap/profile.bw \\\n",
    "    --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2946c15-7597-41a7-8e0e-d3090cf937be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1992, 4, 1282)\n",
      "(1992, 4, 1282)\n"
     ]
    }
   ],
   "source": [
    "#To run modisco, the scores have to be saved as a numpy array. \n",
    "!{SRC_DIR}/shapToNumpy.py \\\n",
    "    --h5 {WORKING_DIRECTORY}/shap/profile.h5 \\\n",
    "    --seqs {WORKING_DIRECTORY}/shap/seq.npy \\\n",
    "    --scores {WORKING_DIRECTORY}/shap/scores.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f051d826-565c-4932-8c77-b956da13f937",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2000 positive seqlets\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/n/projects/cm2363/utils/src/anaconda3/envs/bpreveal/bin/modisco\", line 103, in <module>\n",
      "    pos_patterns, neg_patterns = modiscolite.tfmodisco.TFMoDISco(\n",
      "  File \"/n/projects/cm2363/utils/src/anaconda3/envs/bpreveal/lib/python3.10/site-packages/modiscolite/tfmodisco.py\", line 310, in TFMoDISco\n",
      "    pos_patterns = seqlets_to_patterns(seqlets=pos_seqlets,\n",
      "  File \"/n/projects/cm2363/utils/src/anaconda3/envs/bpreveal/lib/python3.10/site-packages/modiscolite/tfmodisco.py\", line 215, in seqlets_to_patterns\n",
      "    patterns = _patterns_from_clusters(filtered_seqlets, \n",
      "  File \"/n/projects/cm2363/utils/src/anaconda3/envs/bpreveal/lib/python3.10/site-packages/modiscolite/tfmodisco.py\", line 106, in _patterns_from_clusters\n",
      "    pattern = aggregator.merge_in_seqlets_filledges(\n",
      "  File \"/n/projects/cm2363/utils/src/anaconda3/envs/bpreveal/lib/python3.10/site-packages/modiscolite/aggregator.py\", line 100, in merge_in_seqlets_filledges\n",
      "    alnmt, revcomp_match, alnmt_score = _align_patterns(parent_pattern, \n",
      "  File \"/n/projects/cm2363/utils/src/anaconda3/envs/bpreveal/lib/python3.10/site-packages/modiscolite/aggregator.py\", line 81, in _align_patterns\n",
      "    best_crossmetric, best_crossmetric_argmax = metric(fwd_data_child, \n",
      "  File \"/n/projects/cm2363/utils/src/anaconda3/envs/bpreveal/lib/python3.10/site-packages/modiscolite/affinitymat.py\", line 136, in jaccard\n",
      "    _jaccard(X, Y, seqlet_neighbors, scores)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!modisco motifs --sequences {WORKING_DIRECTORY}/shap/seq.npy \\\n",
    "    --attributions {WORKING_DIRECTORY}/shap/scores.npy \\\n",
    "    --max_seqlets 2000 \\\n",
    "    --output {WORKING_DIRECTORY}/modisco/profile.h5 \\\n",
    "    --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a16b21e1-89cd-4c66-ad25-502c78a7dcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!modisco report \\\n",
    "    --h5py {WORKING_DIRECTORY}/modisco/profile.h5 \\\n",
    "    --output {WORKING_DIRECTORY}/modisco/profile/ \\\n",
    "    --suffix profile/ \\\n",
    "    --meme_db /n/data1/JASPAR/2020/JASPAR2020_CORE_vertebrates_redundant_pfms.meme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6912c301-61c9-400a-8ec7-ce93337037b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d17cb5-debd-43b6-be03-be768c365c70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e57ccc-04ca-4ccb-976f-d5b230ded19c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
