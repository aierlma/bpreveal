\documentclass{article}
\usepackage{listings}

\begin{document}

\section{Purpose}
BPReveal is an expansion of the chrombpnet-lite repository, designed to allow for more flexibility. 
The two main changes are the addition of multi-task models, and a generalization of the regression step. 
The general workflow is the following:

\begin{enumerate}
    \item Prepare bigwig tracks and select the regions you are interested in. There are some utilities for this in BPReveal, but you are mostly on your own for this stage. 
    \item Train a bias (AKA solo) model. 
    \item Train a transformation model to match the bias model to the experimental data. 
    \item Train a residual model to explain non-bias parts of the experimental data. 
    \item Measure the performance of the full model. 
    \item Make predictions from the full model and residual model.
    \item Generate importance scores from the residual model, either one-dimensionally, as is usual, or by making two-dimensional PISA plots. 
    \item Run MoDISco. 
\end{enumerate}

\section{Philosophy}
These are the guidelines for code design in chrombpnet-heavy:

\begin{itemize}
    \item Make each program do one thing well. To do a new job, build afresh rather than complicate old programs by adding new features.
    \item Expect the output of every program to become the input to another, as yet unknown, program. Don't clutter the output with extraneous information. Don't insist on interactive input. 
    \item Explicit is better than implicit. Wherever possible, do not allow for defaults when a value is not specified.  (Looking at you, MoDISco!)
    \item Flat is better than nested. Write code that has minimal architectural overhead. 
    \item Errors should never pass silently.
    \item If the implementation is hard to explain, it's a bad idea.
    \item The API should mirror the CLI. 
\end{itemize}


\section{Programs}
BPReveal includes the following core programs:
\begin{description}
    \item [trainSoloModel.py] Takes in a bias training input configuration and trains up a seqmodel to predict the bias track. Saves the seqmodel to disk, along with information from the training phase. 
    \item [trainTransformationModel.py] Takes in a bias model and the actual experimental data. Derives a relation to best fit the bias profile onto the experimental data. Saves a new model to disk, adding a simple layer or two to do the regression. 
    \item [trainCombinedModel.py] Takes a regressed bias model and experimental data and builds a seqmodel to explain the residuals. Saves the model to disk. 
    \item [makePredictionsBed.py] Takes a trained chrombpnet model and predicts over the given regions. 
    \item [makePredictionsFasta.py] Takes a trained chrombpnet model and predicts on sequences given as a fasta file.
    \item [interpretFlat.py] Generates shap scores of the same type as BPNet - hypothetical contributions for each base are written to a modisco-compatible h5. 
    \item [runModisco.py] Runs modisco on the importance score h5 file.
    \item [interpretPisa.py] Runs an all-to-all shap analysis on the given regions. 
\end{description}

And the following utilities:
\begin{description}
    \item [metrics.py] Generates a suite of metrics about how good the model's predictions are. 
    \item [predictToBigwig.py] Takes the .hdf5 file generated by the predict step and converts one track from it into a bigwig file.
    \item [shapToBigwig.py] Converts a shap hdf5 file into a bigwig track for visualization. 
    \item [generateBackgroundRegions.py] Finds regions in the genome without peaks, used to select regions to train up your bias (solo) model.
    \item [lengthCalc.py] Given the parameters of a network, like input filter width, number of layers &c., determine the input width or output width.
    \item [makeLossPlots.py] Once you've trained a model, you can run this on the history file to get plots of all of the components of the loss. 
    \item [prepareBed.py] Given a set of regions and data tracks, reject regions that have too few reads, or that have unmappped bases in the genome.
    \item [showModel.py] Make a pretty picture of your model.
\end{description}

\section{Setup}
BPReveal requires just a few libraries, and I use conda to manage my environment. You can also install these with pip. 
\begin{itemize}
    \item python 3.10 or later
    \item modisco, only needed if you want to do motif identification
    \item pyBigWig, for reading and writing bigwig files
    \item pysam, to read in fasta files
    \item tensorflow 2.8.0 or later (This also installs numpy, scipy, and h5py)
    \item tqdm, for progress bars
\end{itemize}

You can, of course, install any other packages you like. 
I'm fond of jupyter lab for doing analysis, and I use matplotlib for plotting. 
You may find pyBedTools helpful, but I ran into compatibility issues so I do all my bed processing manually. 





\section{Input specification}
In this section, I will provide detailed specifications for all of the input files, with particular emphasis on configuration json files.

\subsection{Solo training input configuration}
A solo training input configuration file is a JSON file that specifies what data should be used to train up the solo model.
It shall contain exactly one regions section, and one input track section for each task that the solo model is being trained on. 

\begin{lstlisting}
<solo-training-input-configuration> ::= 
   {<solo-settings-section> , <regions-section>, 
     <head-section>, <verbosity-section>}

<solo-settings-section> ::= 
    "settings" : {<solo-settings-contents>}

<regions-section> ::= 
    "regions" : [<individual-bed-list>]

<individual-bed-list> ::= 
    <individual-bed> 
  | <individual-bed>, <individual-bed-list>

<individual-bed> ::= 
    {"bed-file" : <file-name>,
     "split" : <split>,
     "absolute-sampling-weight" : <number>,
     "max-jitter" : <integer>}

<split> ::= "train"
  |  "val" 

<head-section> ::= 
  "heads" : [<head-list>]

<head-list> ::= 
    <individual-head>
  | <individual-head>, <head-list>

<individual-head> ::=
    {
      "bigwig-files" : [<bigwig-list>],
      "profile-loss-weight" : <number>,
      "counts-loss-weight" : <number>,
      "head-name" : <string>
    }

<bigwig-list> ::=
    <file-name> 
  | <file-name>, <bigwig-list>

<solo-settings-contents> ::= 
    {"genome" : <file-name>, 
     "output-prefix" : <string>, 
     "epochs" : <integer>, 
     "early-stopping-patience" : <integer>, 
     "batch-size" : <integer>, 
     "learning-rate" : <number>, 
     "learning-rate-plateau-patience" : <integer>,
     "architecture" : <solo-architecture-specification> } 

<solo-architecture-specification> ::= 
    <solo-bpnet-architecture-specification>

<solo-bpnet-architecture-specification> ::= 
    {"architecture-name" : "bpnet",
    "input-length" : <integer>, 
    "output-length" : <integer>,
    "model-name" : <string>,
    "model-args" : <string>,
    "filters" : <integer>,
    "layers" : <integer>,
    "input-filter-width" : <integer>,
    "output-filter-width" : <integer>}

<verbosity-section> ::= 
    "verbosity" : <verbosity-level>

<verbosity-level> ::= "DEBUG"
  | "INFO"
  | "WARN"
\end{lstlisting}

\begin{enumerate}
    \item The split of a bed file determines if it is part of the training set or validation set. The training set is used to optimize the network, and the validation set is used to benchmark the model during training. You should not expose test data to the model at all during training. 
    \item The profile-loss-weight is simply a scalar that the profile loss is multiplied by. This comes in handy when you're training on two datasets with disparate coverage. Since the MNLL loss is proportional to the number of reads, a track with higher coverage will dominate the loss. Instead of calculating this a priori, I find it easiest to start training the model, look at the loss values, and then pick multipliers that will make them about even. 
    \item The counts-loss-weight is similar to profile-loss-weight, but do keep in mind that you need to set it even when you're training a single output head, since the mean squared error value of the counts prediction tends to be minuscule compared to the MNLL loss of the profile. Again, instead of calculating it a priori, I start training with an initial guess and then refine the value later. 
    \item The genome is the fasta-format file containing the whole genome for your organism. 
    \item output-prefix is the file name where you want your model saved. 
    \item early-stopping-patience controls how long the network should wait for an improvement in the loss. I recommend a bit more than double the learning-rate-plateau-patience, on the order of 11. 
    \item batch-size determines how many regions the network will look at simultaneously during training. It doesn't really matter, but if you make it too big your data won't fit on the GPU and if you make it too small your network will take an eternity to train. I like 64 or so. 
    \item learning-rate determines how aggressive the optimizer will be as the network trains. 0.004 is a good bet. (Note that the LR will decrease during training because of the plateau patience.)
    \item learning-rate-plateau-patience controls how many epochs must pass without improvement before the optimizer decreases the learning rate. I recommend 5 or so. 

    \item The architecture name is a future-proofing argument that will determine what type of network you want. Currently, only the basic bpnet-style architecture is supported. 
    \item input-length is the width of the input sequence that will be fed into the network. You can use the lengthCalc.py script to calculate this based on a desired profile width and architecture.
    \item output-length is the width of the predicted profile. This is usually on the order of 1000.
    \item model-name is just a string that is stored along with the model. BPNet-heavy does not use it internally.
    \item model-args is a future-proofing argument. If there is a new feature added to a particular architecture, the model-args string will be passed to the architecture and the architecture may do with that string as it pleases. Currently, this serves no purpose. 
    \item filters is the number of convolutional filters at each layer. The more filters you add, the more patterns the model will try to learn. Typically this is between 32 and 128, smaller for simpler tasks. 
    \item input-filter-width is the size of the very first motif-scanning layer in BPNet. Lately, there's been a trend of making this small, on the order of 7. 
    \item output-filter-width is the width of the very last convolution, the one that actually results in the predicted profile. This layer is placed at the very bottom of the dilated layers. I use a width of 75, but many people use smaller output widths. 
\end{enumerate}

\subsection{Transformation input configuration}
The transformation input file is a JSON file that names a solo model and gives the experimental data that it should be fit to. 

\begin{lstlisting}
<transformation-input-configuration> ::=
    {"settings" : <transformation-settings-section>, 
        <beds-section>, 
        <head-section>, <verbosity-section>}

<transformation-settings-section> ::=
     {"genome" : <file-name>,
      "output-prefix" : "<string>", 
      "epochs" : <integer>, 
      "early-stopping-patience" : <integer>, 
      "batch-size" : <integer>, 
      "learning-rate" : <number>,
      "learning-rate-plateau-patience" : <integer> 
      "solo-model-file" : <file-name>,
      "sequence-input-length" : <integer>,
      "output-length" : <integer>,
      "profile-architecture" : <transformation-architecture-specification>, 
      "counts-architecture" : <transformation-architecture-specification> } 

<transformation-architecture-specification> ::= 
    <simple-transformation-architecture-specification>
  | "name" : "passthrough"

<simple-transformation-architecture-specification> ::= 
    "name" : "simple",
    "types" : [<list-of-simple-transformation-types>]

<list-of-simple-transformation-types> ::= 
    <simple-transformation-type>
  | <simple-transformation-type>, <list-of-simple-transformation-types>

<simple-transformation-type> ::= 
    "linear"
  | "sigmoid"
  | "relu"

\end{lstlisting}

This code does not support using an experimental bias track as the input to the 
transformation - it must be a solo model that uses sequence as input.
\begin{enumerate}
    \item solo-model-file is the name of the file (or directory, since that's how keras likes to save models) that contains the solo model. 
    \item A passthrough transformation does nothing to the solo model, it doesn't regress anything. 
    \item A simple transformation applies the specified functions to the output of the solo model, and adjusts the parameters to best fit the experimental data. A linear model applies y=mx+b to the solo predictions (which, remember, are in log-space), a sigmoid applies y = m1 *sigmoid(m2x+b2) + b1, and a relu applies y = m1 * relu(m2x+b2) + b1. In other words, there's a linear model both before and after the sigmoid or relu activation. Generally, you need to use these more complex functions when the solo model is not a great fit for the experimental bias. 
\end{enumerate}


\subsection{Combined training input configuration}
The full chrombpnet model, known as a combined model is specified by a JSON file, 
much like the bias file.

\begin{lstlisting}

<combined-training-input-configuration> ::= 
   {<combined-settings-section> , <beds-section>, 
     <combined-head-section>, <verbosity-section>}

<combined-head-section> ::= 
  "heads" : [<combined-head-list>]

<combined-head-list> ::= 
    <combined-individual-head>
  | <combined-individual-head>, <combined-head-list>

<combined-individual-head> ::=
    {
      "bigwig-files" : [<bigwig-list>],
      "profile-loss-weight" : <number>,
      "counts-loss-weight" : <number>,
      "head-name" : <string>,
      "use-bias-counts" : <boolean>
}

<combined-settings-section> ::= 
    "settings" : {<combined-settings-contents>}

<combined-settings-contents> ::= 
    {"genome" : <file-name>, 
     "output-directory" : "<string>",
     "epochs" : <integer>, 
     "early-stopping-patience" : <integer>, 
     "batch-size" : <integer>, 
     "learning-rate" : <number>, 
     "learning-rate-plateau-patience" : <integer>,
     "transformation-model" : <transformation-combined-settings>,
     "architecture" : <combined-architecture-specification> } 

<transformation-combined-settings> ::= 
   { "transformation-model-file" : <file-name>, 
     "input-length" : <integer>
  }

<combined-architecture-specification> ::= 
    <solo-bpnet-architecture-specification>

<combined-bpnet-architecture-specification> ::= 
    {"architecture-name" : "bpnet",
    "input-length" : <number>, 
    "output-length" : <number>,
    "model-name" : <string>,
    "model-args" : <string>,
    "filters" : <number>,
    "layers" : <number>,
    "input-filter-width" : <number>,
    "output-filter-width" : <number>}
\end{lstlisting}

\begin{enumerate}
    \item use-bias-counts selects if you want to add the counts prediction from the transformation model, and the appropriateness of this flag will depend on the nature of your bias. If the bias is a constant background signal, then it makes sense to subtract the bias contribution to the counts. However, if your bias is multiplied by the underlying biology, then you probably shouldn't add in the bias counts since they won't affect the actual experiment. 
\end{enumerate}

\subsection{Prediction input configuration}
This is the JSON file given to makePredictionsBed. It names the model to use and the predictions to make. 

\begin{lstlisting}
<prediction-input-configuration>::=
    {<prediction-settings-section>, <prediction-bed-section>,
    <verbosity-section>}

<prediction-settings-section> ::= "settings" : {
    "output-h5" : <file-name>,
    "genome" : <file-name>,
    "batch-size" : <integer>,
    "heads" : <integer>,
    "architecture" : <prediction-model-settings> }

<prediction-bed-section> ::=
    "bed-file" : <file-name>

<prediction-model-settings> ::={
    "model-file" : <file-name>,
    "input-length" : <integer>,
    "output-length" : <integer> }
\end{lstlisting}
\begin{enumerate}

    \item heads just gives the number of output heads for your model. 

\end{enumerate}

This program will produce an hdf5-format file containing the predicted values. It is organized as follows:

\begin{itemize}
    \item "chrom\_names" is a list of strings that give you the meaning of each index in the coords\_chrom dataset. This is particularly handy when you want to make a bigwig file, since you can extract a header from this data. 
    \item "chrom\_size", the size of each chromosome in the same order as chrom\_names. Mostly used to create bigwig headers. 
    \item "coords\_chrom" a list of integers, one for each region predicted, that gives the chromosome index (see chrom\_names) for that region. 
    \item "coords\_start", the start base of each predicted region. 
    \item "coords\_stop", the end point of each predicted region.
    \item A subgroup for each output head of the model. The subgroups are named "head\_N", where N is 0, 1, 2, etc. 
        \begin{itemize}
            \item "logcounts", a vector of shape (numRegions,) that gives the logcounts value for each region. 
            \item "logits", the array of logit values for each track for each region. The shape is (numRegions x outputWidth x numTasks). Don't forget that you must calculate the softmax on the whole set of logits, not on each task's logits independently.
        \end{itemize} 

\end{itemize}

\subsection{Prediction from fasta configuration}
This is the JSON file given to the prediction from fasta script. It names the model to use and the file that contains the sequences to run predictions on.

\begin{lstlisting}
<prediction-fasta-input-configuration> ::=
    { <prediction-fasta-settings-section>, <prediction-fasta-input-section>,
        <verbosity-section> }

<prediction-fasta-settings-section> ::= "settings" : {
    "output-h5" : <file-name>,
    "batch-size" : <integer>,
    "heads" : <integer>,
    "architecture" : <prediction-model-settings> }

<prediction-fasta-input-section> ::=
    "fasta-file" : <file-name>
\end{lstlisting}

This program will produce an hdf5-format file containing the description lines from the original fasta, as well as the predicted logcounts and logits.
It is structured so:

\begin{itemize}
    \item "descriptions", a list of strings of length (numRegions,). Each string corresponds to one description line (i.e., a line starting with \texttt{>}). 
    \item A subgroup for each output head of the model. The subgroups are named "head\_N", where N is 0, 1, 2, etc. 
        \begin{itemize}
            \item "logcounts", a vector of shape (numRegions,) that gives the logcounts value for each region. 
            \item "logits", the array of logit values for each track for each region. The shape is (numRegions x outputWidth x numTasks). Don't forget that you must calculate the softmax on the whole set of logits, not on each task's logits independently.
        \end{itemize} 
\end{itemize}

        


\subsection{Interpret PISA configuration}

This is the JSON file given to the PISA interpretation tool. 
\begin{lstlisting}
<pisa-configuration> ::= {
    "genome" : <file-name>,
    "bed-file" : <file-name>,
    "model-file" : <file-name>,
    "input-length" : <integer>,
    "output-length" : <integer>,
    "heads" : <integer>,
    "head-id" : <integer>,
    "task-id" : <integer>,
    "output-h5" : <integer>,
    "num-shuffles" : <integer>,
    <verbosity-section>
}
\end{lstlisting}

It produces an hdf5 format which is organized as follows:
\begin{itemize}
    \item "head-id", an integer representing which head of the model was used to generate the data.
    \item "task-id", an integer giving the task number within the specified head. 
    \item "chrom\_names", a list of strings giving the name of each chromosome. This is used to figure out which chromosome each number in coords\_chrom corresponds to. 
    \item "chrom\_sizes", a list of integers giving the size of each chromosome. This is mostly here as a handy reference when you want to make a bigwig file. 
    \item "coords\_base", the center point for each of the regions in the table of PISA values. 
    \item "coords\_chrom", the chromosome on which each PISA vector is found. 
    \item "sequence", a one-hot encoded array representing the sequence under each PISA value. The shape is (num regions * receptive-field * 4). Note that this is receptive field, not input width, since each base being shapped will only be affected by bases in its receptive field, and there's no reason to store the noise. 
    \item "shap", a table of the shap scores. The shape is the same as the sequence table, and each position in the shap table represents the corresponding base in the sequence table. These values are contribution scores to the difference-from-reference of the logit at this base. 

\end{itemize}



\subsection{Prepare bed configuration}
\emph{This is a utility program, not part of the main BPReveal. You are responsible for generating bed files with regions.}

This is the JSON file given to the input preparation script. It splits your regions into 
test, train, and validation regions, and optionally applies some filtering. 

\begin{lstlisting}
<prepare-bed-configuration> ::={
    <counts-cutoff-section>
    "bigwigs" : [<list-of-bigwigs>],
    "splits" : {<split-settings>},
    "genome" : <file-name>,
    "output-width" : <integer>,
    "input-width" : <integer>,
    "max-jitter" : <integer>,
    <output-file-name-section>,
    "resize-mode" : <resize-mode>
    }

<resize-mode> ::= 
    "none"
  | "center"
  | "start"
  | "peak"

<output-file-name-section> ::=
    "output-prefix" : "<string>"
  | "output-train" : <file-name>,
    "output-val" : <file-name>,
    "output-test" : <file-name>

<counts-cutoff-section> ::=
    <empty>
  | "counts-window-type" : <counts-window-type>,
    "maximum-counts" : [<list-of-integers>],


<counts-window-type> ::=
    "output"
  | "output+jitter"
  | "input" 
  | "input+jitter"


<list-of-bigwigs> ::= 
    <file-name>, <list-of-bigwigs>
  | <file-name>

<split-settings> ::=
    <split-by-chromosome-settings>
  | <split-by-name-settings>
  | <split-by-bed-settings>

<split-by-chromosome-settings> ::=
    "train-chroms" : [<list-of-strings>],
    "val-chroms" : [<list-of-strings> ],
    "test-chroms" : [<list-of-strings> ],
    "regions" : [<list-of-bed-files>]

<split-by-bed-settings> ::=
    "train-regions" : [<list-of-bed-files>],
    "val-regions" : [<list-of-bed-files>],
    "test-regions" : [<list-of-bed-files>]

<split-by-name-settings> ::=
    "regions" : [<list-of-bed-files>],
    "test-regex" : "<string>",
    "train-regex" : "<string>",
    "val-regex" : "<string>"

<list-of-bed-files> ::=
    <file-name>, <list-of-bed-files>
  | <file-name>

\end{lstlisting}

\section{Model architectures}

The precise details of the model architectures can be found in models.py, but they share some common themes. 
Every model that ever gets saved to disk accepts a one-hot encoded sequence as input, and produces outputs that are grouped into ``heads''. 
A model may generate any number of heads, and the heads may have different sizes. 
In general, each head should represent one set of DNA fragments. For example, an experiment that produces cut sites on the + and - strand of DNA produces
two tracks, but the tracks represent two ends of the same fragments. So these two tracks would be in the same head. 
However, if you have an experiment where it's appropriate to split fragments into ``short'' (100-500 bp) and ``long'' (1 kb to 10 kb), then 
those tracks do not represent the same fragments, so they should be in different heads. 

If you have done ChIP-nexus on three different factors, then you'd have three heads, each one corresponding to a different factor, and each head would predict both the + and - strand data for that factor. 

If you're not sure if you can combine your data under one output head, it's much safer to split the data into multiple heads. 

A head contains a profile prediction and a counts prediction. The profile prediction is a tensor of shape (batch-size x) number-of-tracks x output-width, and each value in this tensor is a logit. 
Note that the WHOLE profile prediction should be considered when taking the softmax. 
That is to say, the profile of the first track is NOT exp(counts) * softmax(profile[0,:]), but rather you have to take the softmax first and then slice out the profile: exp(counts) * softmax(profile)[:,0]

Of course, if the profile only has one track, this distinction is vacuous. 
The counts output is a scalar that represents the natural logarithm of the number of reads predicted for the current region. 

It is possible to add more model architectures, but currently the program only supports a BPNet-style architecture. You can take a look at soloModel in models.py for details on how it works. 




\end{document}
