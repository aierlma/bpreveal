#!/usr/bin/env python3

import cwmUtils
import numpy as np
import csv
import argparse
import logging


def recordToPatternID(record):
    """Come up with an identifier that uniquely identifies a particular pattern.
    Since a single csv should only represent one modisco run, it's safe to just
    mash the metacluster and pattern names together. We can't use short-name because
    somebody could give the same name to different patterns."""

    mn = record["metacluster-name"].split("_")[0]
    pn = record["pattern-name"].split("_")[1]
    return mn + pn


def readCsv(fname):
    """Reads in a csv file generated by the cwm seqlet analysis and scanning tools.
    returns a three-tuple. The first contains the field names from the csv file, in order.
    The second is a list of dicts, each dict corresponding to one field in the csv.
    The dicts map field names (strings) to the contents of the corresponding column for that
    record.
    The third value returned is a list of the unique pattern identifiers among the records;
    these names are generated by recordToPatternID
    Each record in the returned list of records contains a field that was not present in the
    initial CSV, this field is called _TMPNAME. This field contains the combined pattern
    identifier."""

    records = []
    patternIDs = []
    with open(fname, "r", newline='') as fp:
        fieldNames = [x.strip() for x in fp.readline().split(',')]
        reader = csv.DictReader(fp, fieldnames=fieldNames)
        for row in reader:
            tmpName = recordToPatternID(row)
            row["_TMPNAME"] = tmpName
            records.append(row)

            if tmpName not in patternIDs:
                patternIDs.append(tmpName)

    return fieldNames, records, patternIDs


def addFieldNameQuantileMetadata(standardRecords, sampleRecords, patternID, readName, writeName):
    standardValues = []
    for r in standardRecords:
        if r["_TMPNAME"] == patternID:
            standardValues.append(float(r[readName]))
    sampleValues = []
    for r in sampleRecords:
        if r["_TMPNAME"] == patternID:
            sampleValues.append(float(r[readName]))

    quantileMap = cwmUtils.arrayQuantileMap(np.array(standardValues),
                                   np.array(sampleValues))
    readHead = 0
    for r in sampleRecords:
        if r["_TMPNAME"] == patternID:
            r[writeName] = quantileMap[readHead]
            readHead += 1


def addFieldQuantileData(standardRecords, sampleRecords, recordNames, readName, writeName):
    for rn in recordNames:
        addFieldNameQuantileMetadata(standardRecords, sampleRecords, rn, readName, writeName)


def addAllMetadata(standardRecords, sampleRecords, recordNames, readNames, writeNames):
    for i in range(len(readNames)):
        addFieldQuantileData(standardRecords, sampleRecords,
                             recordNames, readNames[i], writeNames[i])


def writeCsv(records, fieldNames, fname):
    with open(fname, "w", newline='') as fp:
        writer = csv.DictWriter(fp, fieldnames=fieldNames, extrasaction='ignore')
        writer.writeheader()
        for r in records:
            writer.writerow(r)


def main():
    parser = argparse.ArgumentParser(description="Given csv files generated by cwmPrepare "
                                     "and cwmScan, add quantile information about each motif "
                                     "hit for downstream analysis.")
    parser.add_argument("--seqlet-csv", dest="seqletCsvFname", help="The name of the seqlet csv "
                        "file generated by cwmPrepare.py (or cwmScan if run with "
                        "seqlet-settings).", required=True)
    parser.add_argument("--scan-csv", dest="scanCsvFname", help="The name of the csv file "
                        "generated by cwmScan.py", required=True)
    parser.add_argument("--seqlet-out", dest='seqletOutFname', help="Instead of overwriting "
                        "seqlet-csv, write the results to this file. If omitted, edit seqlet-csv "
                        "in place.", required=False)
    parser.add_argument("--scan-out", dest='scanOutFname', help="Instead of overwriting scan-csv "
                        "write them to this file. If omitted, edit scan-csv in place.",
                        required=False)
    parser.add_argument("--verbose", help="Include more debugging information.",
                        action='store_true')

    args = parser.parse_args()
    if args.verbose:
        logging.basicConfig(level=logging.INFO)
    else:
        logging.basicConfig(level=logging.WARNING)
    seqletInFname = args.seqletCsvFname
    scanInFname = args.scanCsvFname
    seqletOutFname = args.seqletOutFname
    if seqletOutFname is None:
        seqletOutFname = seqletInFname
    scanOutFname = args.scanOutFname
    if scanOutFname is None:
        scanOutFname = scanInFname

    # Now read in the data.
    logging.info("Reading in seqlet csvs")
    seqletFields, seqletRecords, seqletPatternNames = readCsv(seqletInFname)
    scanFields, scanRecords, scanPatternNames = readCsv(scanInFname)
    logging.info("Finished reading.")
    readNames = ["L1-score", "ic-match", "contrib-match"]
    writeNames = [x + "-quantile" for x in readNames]
    logging.info("Annotating seqlet csvs")
    addAllMetadata(seqletRecords, seqletRecords, seqletPatternNames, readNames, writeNames)
    logging.info("Annotating scanned hit csvs")
    addAllMetadata(seqletRecords, scanRecords, scanPatternNames, readNames, writeNames)

    # Now we just have to write the records out.
    logging.info("Writing annotated seqlet csv")
    writeCsv(seqletRecords, seqletFields + writeNames, seqletOutFname)
    logging.info("Writing annoted scan csv")
    writeCsv(scanRecords, scanFields + writeNames, scanOutFname)


if __name__ == "__main__":
    main()
