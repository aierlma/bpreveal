#!/usr/bin/env python3

import bpreveal.motifUtils as motifUtils
import numpy as np
import csv
import argparse
import logging


def recordToPatternID(record):
    """Come up with an identifier that uniquely identifies a particular pattern.
    Since a single csv should only represent one modisco run, it's safe to just
    mash the metacluster and pattern names together. We can't use short-name because
    somebody could give the same name to different patterns."""

    mn = record["metacluster_name"].split("_")[0]
    pn = record["pattern_name"].split("_")[1]
    return mn + pn


def readTsv(fname):
    """Reads in a tsv file generated by the motif seqlet cutoff and scanning tools.
    Returns a three-tuple. The first contains the field names from the tsv file, in order.
    The second is a list of dicts, each dict corresponding to one field in the tsv.
    The dicts map field names (strings) to the contents of the corresponding column for that
    record.
    The third value returned is a list of the unique pattern identifiers among the records;
    these names are generated by recordToPatternID
    Each record in the returned list of records contains a field that was not present in the
    initial tsv, this field is called _TMPNAME. This field contains the combined pattern
    identifier."""

    records = []
    patternIDs = []
    with open(fname, "r", newline='') as fp:
        fieldNames = [x.strip() for x in fp.readline().split('\t')]
        reader = csv.DictReader(fp, fieldnames=fieldNames, delimiter='\t')
        for row in reader:
            tmpName = recordToPatternID(row)
            row["_TMPNAME"] = tmpName
            records.append(row)

            if tmpName not in patternIDs:
                patternIDs.append(tmpName)

    return fieldNames, records, patternIDs


def addFieldNameQuantileMetadata(standardRecords, sampleRecords, patternID, readName, writeName):
    standardValues = []
    for r in standardRecords:
        if r["_TMPNAME"] == patternID:
            standardValues.append(float(r[readName]))
    sampleValues = []
    for r in sampleRecords:
        if r["_TMPNAME"] == patternID:
            sampleValues.append(float(r[readName]))

    quantileMap = motifUtils.arrayQuantileMap(np.array(standardValues),
                                   np.array(sampleValues))
    readHead = 0
    for r in sampleRecords:
        if r["_TMPNAME"] == patternID:
            r[writeName] = quantileMap[readHead]
            readHead += 1


def addFieldQuantileData(standardRecords, sampleRecords, recordNames, readName, writeName):
    for rn in recordNames:
        addFieldNameQuantileMetadata(standardRecords, sampleRecords, rn, readName, writeName)


def addAllMetadata(standardRecords, sampleRecords, recordNames, readNames, writeNames):
    for i in range(len(readNames)):
        addFieldQuantileData(standardRecords, sampleRecords,
                             recordNames, readNames[i], writeNames[i])


def writeTsv(records, fieldNames, fname):
    with open(fname, "w", newline='') as fp:
        writer = csv.DictWriter(fp, fieldnames=fieldNames, extrasaction='ignore',
                                delimiter='\t')
        writer.writeheader()
        for r in records:
            writer.writerow(r)


def main():
    parser = argparse.ArgumentParser(description="Given tsv files generated by motifSeqletCutoffs"
                                     "and motifScan, add quantile information about each motif "
                                     "hit for downstream analysis.")
    parser.add_argument("--seqlet-tsv", dest="seqletTsvFname", help="The name of the seqlet tsv "
                        "file generated by motifSeqletCutoffs.py (or motifScan.py if run with "
                        "pattern-cutoff-settings).", required=True)
    parser.add_argument("--scan-tsv", dest="scanTsvFname", help="The name of the tsv file "
                        "generated by motifScan.py", required=True)
    parser.add_argument("--seqlet-out", dest='seqletOutFname', help="Instead of overwriting "
                        "seqlet-tsv, write the results to this file. If omitted, edit seqlet-tsv "
                        "in place.", required=False)
    parser.add_argument("--scan-out", dest='scanOutFname', help="Instead of overwriting scan-tsv "
                        "write them to this file. If omitted, edit scan-tsv in place.",
                        required=False)
    parser.add_argument("--verbose", help="Include more debugging information.",
                        action='store_true')

    args = parser.parse_args()
    if args.verbose:
        logging.basicConfig(level=logging.INFO)
    else:
        logging.basicConfig(level=logging.WARNING)
    seqletInFname = args.seqletTsvFname
    scanInFname = args.scanTsvFname
    seqletOutFname = args.seqletOutFname
    if seqletOutFname is None:
        seqletOutFname = seqletInFname
    scanOutFname = args.scanOutFname
    if scanOutFname is None:
        scanOutFname = scanInFname

    # Now read in the data.
    logging.info("Reading in seqlet tsvs")
    seqletFields, seqletRecords, seqletPatternNames = readTsv(seqletInFname)
    scanFields, scanRecords, scanPatternNames = readTsv(scanInFname)
    logging.info("Finished reading.")
    readNames = ["contrib_magnitude", "seq_match", "contrib_match"]
    writeNames = [x + "_quantile" for x in readNames]
    logging.info("Annotating seqlet tsvs")
    addAllMetadata(seqletRecords, seqletRecords, seqletPatternNames, readNames, writeNames)
    logging.info("Annotating scanned hit tsvs")
    addAllMetadata(seqletRecords, scanRecords, scanPatternNames, readNames, writeNames)

    # Now we just have to write the records out.
    logging.info("Writing annotated seqlet tsv")
    writeTsv(seqletRecords, seqletFields + writeNames, seqletOutFname)
    logging.info("Writing annoted scan tsv")
    writeTsv(scanRecords, scanFields + writeNames, scanOutFname)


if __name__ == "__main__":
    main()
