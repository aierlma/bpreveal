#!/usr/bin/env python3
import h5py
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"
os.environ["TF_ENABLE_ONEDNN_OPTS"] = "1"
import numpy as np
import tqdm
from collections import OrderedDict
import modisco
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import logging
import modisco.visualization
from modisco.visualization import viz_sequence

def save_plot(weights, dst_fname):
    """

    """
    logging.info("Writing plot for " + dst_fname)
    colors = {0:'green', 1:'blue', 2:'orange', 3:'red'}
    plot_funcs = {0: viz_sequence.plot_a, 1: viz_sequence.plot_c,
                  2: viz_sequence.plot_g, 3: viz_sequence.plot_t}

    fig = plt.figure(figsize=(20, 2))
    ax = fig.add_subplot(111)
    viz_sequence.plot_weights_given_ax(ax=ax, array=weights,
                                       height_padding_factor=0.2,
                                       length_padding=1.0,
                                       subticks_frequency=1.0,
                                       colors=colors, plot_funcs=plot_funcs,
                                       highlight={}, ylabel="")

    plt.savefig(dst_fname)

def import_shap_scores(
    shap_scores_hdf5, center_cut_size, remove_non_acgt=True):
    """
    Imports the SHAP scores generated/saved by `make_shap_scores.py`, and
    returns the hypothetical importance scores, actual importance scores, and
    one-hot encoded sequences.
    Arguments:
        `shap_scores_hdf5`: path to HDF5 of SHAP scores generated by
            `make_shap_scores.py`
        `center_cut_size`: if specified, keeps only scores/sequences of this
            centered length; by default uses the entire length given in the
            SHAP scores
        `remove_non_acgt`: if True, remove any sequences (after being cut down
            to size) which have a base other than ACGT (e.g. N)
    Returns the hypothetical importance scores, actual importance scores,
    corresponding one-hot encoded input sequences, and coordinates. The first
    three are N x L x 4 arrays, and the last is an N x 3 object array.
    where L is the cut size (or default size).
    """
    score_reader = h5py.File(shap_scores_hdf5, "r")

    # For defining shapes
    num_seqs, input_length, _ = score_reader["hyp_scores"].shape
    cut_start = (input_length // 2) - (center_cut_size // 2)
    cut_end = cut_start + center_cut_size

    # For batching up data loading
    batch_size = min(1000, num_seqs)
    num_batches = int(np.ceil(num_seqs / batch_size))

    # Read in hypothetical scores and input sequences in batches
    hyp_scores = np.empty((num_seqs, center_cut_size, 4))
    act_scores = np.empty((num_seqs, center_cut_size, 4))
    one_hot_seqs = np.empty((num_seqs, center_cut_size, 4))
    coords = np.empty((num_seqs, 3), dtype=object)

    for i in tqdm.trange(num_batches, desc="Importing SHAP scores"):
        batch_slice = slice(i * batch_size, (i + 1) * batch_size)
        hyp_score_batch = score_reader["hyp_scores"][
            batch_slice, cut_start:cut_end
        ]
        one_hot_seq_batch = score_reader["input_seqs"][
            batch_slice, cut_start:cut_end
        ]
        chrom_batch = score_reader["coords_chrom"][batch_slice].astype(str)
        start_batch = score_reader["coords_start"][batch_slice]
        end_batch = score_reader["coords_end"][batch_slice]
        hyp_scores[batch_slice] = hyp_score_batch
        one_hot_seqs[batch_slice] = one_hot_seq_batch
        act_scores[batch_slice] = hyp_score_batch * one_hot_seq_batch
        coords[batch_slice, 0] = chrom_batch
        coords[batch_slice, 1] = start_batch
        coords[batch_slice, 2] = end_batch

    score_reader.close()

    if remove_non_acgt:
        # Remove any examples in which the input sequence is not all ACGT
        mask = np.sum(one_hot_seqs, axis=(1, 2)) == center_cut_size
        hyp_scores, act_scores, one_hot_seqs, coords = \
            hyp_scores[mask], act_scores[mask], one_hot_seqs[mask], coords[mask]

    return hyp_scores, act_scores, one_hot_seqs, coords


def import_tfmodisco_results(tfm_results_path, hyp_scores, one_hot_seqs, center_cut_size):
    """
    Imports the TF-MoDISco results object.
    Arguments:
        `tfm_results_path`: path to HDF5 containing TF-MoDISco results
        `hyp_scores`: hypothetical importance scores used for this run, an
            N x L x 4 array
        `one_hot_seqs`: input sequences used for this run, an N x L x 4 array
        `center_cut_size`: centered cut size of SHAP scores used; the input
            sequences may already have length L equal to this, or if they are
            longer the sequences will be cut
    Although this function is not used to run TF-MoDISco in this script, it can
    be useful for importing the results later (in conjuction with
    `import_shap_scores`).
    """
    assert hyp_scores.shape == one_hot_seqs.shape
    input_length = hyp_scores.shape[1]

    if input_length != center_cut_size:
        # Everything not cut to `center_cut_size`
        assert input_length > center_cut_size
        cut_start = (input_length // 2) - (center_cut_size // 2)
        cut_end = cut_start + center_cut_size
        hyp_scores = hyp_scores[:, cut_start:cut_end]
        one_hot_seqs = one_hot_seqs[:, cut_start:cut_end]

    act_scores = hyp_scores * one_hot_seqs

    track_set = modisco.tfmodisco_workflow.workflow.prep_track_set(
        task_names=["task0"],
        contrib_scores={"task0": act_scores},
        hypothetical_contribs={"task0": hyp_scores},
        one_hot=one_hot_seqs
    )

    with h5py.File(tfm_results_path,"r") as f:
        return modisco.tfmodisco_workflow.workflow.TfModiscoResults.from_hdf5(f, track_set=track_set)

def main(shap_scores_hdf5, outDirName, center_cut_size):
    """
    Takes the set of importance scores generated by `make_shap_scores.py` and
    runs TF-MoDISco on them.
    """
    hyp_scores, act_scores, input_seqs, _ = import_shap_scores(shap_scores_hdf5, center_cut_size)
    task_to_hyp_scores, task_to_act_scores = OrderedDict(), OrderedDict()
    task_to_hyp_scores["task0"] = hyp_scores
    task_to_act_scores["task0"] = act_scores

    # Construct workflow pipeline
    tfm_workflow = modisco.tfmodisco_workflow.workflow.TfModiscoWorkflow(
        sliding_window_size=20,
        max_seqlets_per_metacluster=20000,
    	flank_size=5,
        target_seqlet_fdr=0.05,
    	seqlets_to_patterns_factory=modisco.tfmodisco_workflow.seqlets_to_patterns.TfModiscoSeqletsToPatternsFactory(
            embedder_factory=modisco.seqlet_embedding.advanced_gapped_kmer.AdvancedGappedKmerEmbedderFactory(),
    	    trim_to_window_size=20,
            n_cores = 60,
    	    initial_flank_to_add=5,
    	    final_min_cluster_size=50
    	)
    )

    # Move to output directory to do work
    cwd = os.getcwd()
    os.makedirs(outDirName, exist_ok=True)
    os.chdir(outDirName)

    tfm_results = tfm_workflow(
        task_names=list(task_to_act_scores.keys()),
        contrib_scores=task_to_act_scores,
        hypothetical_contribs=task_to_hyp_scores,
        one_hot=input_seqs)

    os.chdir(cwd)
    logging.info("Saving results to %s" % (outDirName + "/modisco.h5"))
    with h5py.File(outDirName + "/modisco.h5", "w") as f:
        tfm_results.save_hdf5(f)

    ###########################################################################################
    #Loop by metacluster to generate results.
    ###########################################################################################
    metacluster_count = len(tfm_results.metacluster_idx_to_submetacluster_results)

    for mc in range(metacluster_count):
        seqlet_path = f'{outDirName}/metacluster_{mc}_seqlets.txt'
        logging.info("Saving seqlets to %s" % seqlet_path)
        seqlets = \
            tfm_results.metacluster_idx_to_submetacluster_results[mc].seqlets
        bases = np.array(["A", "C", "G", "T"])
        with open(seqlet_path, "w") as f:
            for seqlet in seqlets:
                sequence = "".join(
                    bases[np.argmax(seqlet["sequence"].fwd, axis=-1)]
                )
                example_index = seqlet.coor.example_idx
                start, end = seqlet.coor.start, seqlet.coor.end
                f.write(">example%d:%d-%d\n" % (example_index, start, end))
                f.write(sequence + "\n")

    logging.info("Saving pattern visualizations")
    for mc in range(metacluster_count):
        patterns = (tfm_results
                    .metacluster_idx_to_submetacluster_results[mc]
                    .seqlets_to_patterns_result.patterns)

        # generate .pngs of each motif and write motif seqlet to
        # individual files
        for idx,pattern in enumerate(patterns):
            logging.info(pattern)
            logging.info("pattern idx",idx)
            logging.info(len(pattern.seqlets))

            pattern_seqlet_path = os.path.join(outDirName,
                                               f'metacluster_{mc}_pattern_{idx}_seqlets.txt')
            with open(pattern_seqlet_path, "w") as f:
                for seqlet in pattern.seqlets:
                    sequence = "".join(
                        bases[np.argmax(seqlet["sequence"].fwd, axis=-1)]
                    )
                    example_index = seqlet.coor.example_idx
                    start, end = seqlet.coor.start, seqlet.coor.end
                    f.write(">example%d:%d-%d\n" % (example_index, start, end))
                    f.write(sequence + "\n")

            save_plot(pattern["task0_contrib_scores"].fwd,
                      f'{outDirName}/metacluster_{mc}_contrib_{idx}.png')
            save_plot(pattern["sequence"].fwd,
                      f'{outDirName}/metacluster_{mc}_sequence_{idx}.png')
            save_plot(pattern["task0_contrib_scores"].fwd,
                      f'{outDirName}/metacluster_{mc}_contrib_{idx}.pdf')
            save_plot(pattern["sequence"].fwd,
                      f'{outDirName}/metacluster_{mc}_sequence_{idx}.pdf')

if __name__ == "__main__":
    import json
    import sys
    config = json.load(open(sys.argv[1]))
    shapScoresHdf5 = config["shap-h5"]
    outputFname = config["output-dir"]
    centerCutSize = config["center-cut-size"]
    main(shapScoresHdf5, outputFname, centerCutSize)
